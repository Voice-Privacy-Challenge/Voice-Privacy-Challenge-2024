data_dir: data
results_dir: anon_wav # output example ./data/IEMOCAP_ims_sttts_pc/anon_wav

pipeline: ims_sttts_pc
anon_suffix: !ref _<pipeline>

datasets:
  - name: IEMOCAP_dev
    data: IEMOCAP_dev
  - name: IEMOCAP_test
    data: IEMOCAP_test
  - name: libri_dev
    data: libri_dev
    enrolls: [_enrolls]
    trials: [_trials_f, _trials_m]
  - name: libri_test
    data: libri_test
    enrolls: [_enrolls]
    trials: [_trials_f, _trials_m]
  - name: train-clean-360
    data: train-clean-360

models_dir:  exp/sttts_models
save_intermediate: true
intermediate_dir: !ref exp/anon_pipiline_<pipeline>
modules:
  asr:
    recognizer: ims
    model_path: !ref <models_dir>/asr/asr_branchformer_tts-phn_en.zip
    ctc_weight: 0.2
    utt_start_token: "~"
    utt_end_token: "~#"
    results_path: !ref <intermediate_dir>/transcription/asr_branchformer_tts-phn_en

  speaker_embeddings:
    anonymizer: ims
    vec_type: style-embed
    emb_model_path: !ref <models_dir>/tts/Embedding/embedding_function.pt
    emb_level: spk   # possible: spk, utt
    anon_method: !include:anon_ims_sttts_pc/ims_gan.yaml    # possible: pool, random
      models_dir: !ref <models_dir>
      save_intermediate: !ref <save_intermediate>
      vec_type: !ref <modules[speaker_embeddings][vec_type]>
    extraction_results_path: !ref <intermediate_dir>/original_speaker_embeddings/<modules[speaker_embeddings][vec_type]>_<modules[speaker_embeddings][emb_level]>-level
    anon_results_path: !ref <intermediate_dir>/anon_speaker_embeddings/<modules[speaker_embeddings][vec_type]>_<modules[speaker_embeddings][emb_level]>-level

    # pool_anon_settings are only used if anon_method == pool
    pool_anon_settings:
      pool_data_dir: !ref <data_dir>/libritts_train_other_500
      pool_vec_path: !ref <intermediate_dir>/original_speaker_embeddings/style-embed_spk-level/pool_embeddings
      N: 200
      N_star: 100
      distance: plda    # possible: plda, cosine
      plda_dir: !ref <models_dir>/distances/plda/libritts_train_other_500_xvector
      cross_gender: false
      proximity: farthest    # possible: farthest, nearest, center
      scaling: maxmin    # possible: none, maxmin, mean
      stats_per_dim_path: !ref <models_dir>/anonymization/stats_per_dim.json

    # random_anon_settings are only used if anon_method == random
    random_anon_settings:
      in_scale: true
      stats_per_dim_path: !ref <models_dir>/anonymization/stats_per_dim.json

    # gan_anon_settings are only used if anon_method == gan
    gan_anon_settings:
      vectors_file: !ref <models_dir>/anonymization/style-embed_wgan_generated_vectors.pt
      gan_model_path: !ref <models_dir>/anonymization/style-embed_wgan.pt
      num_sampled: 5000
      sim_threshold: 0.7

  prosody:
    extractor_type: ims
    aligner_model_path: !ref <models_dir>/tts/Aligner/aligner.pt
    extraction_results_path: !ref <intermediate_dir>/original_prosody/ims_extractor
    #anonymizer_type: ims  # uncomment following lines to use random offset modification
    #random_offset_lower: null
    #random_offset_higher: null
    #anon_results_path: anon_prosody/random_offsets

  tts:
    synthesizer: ims
    fastspeech_path: !ref <models_dir>/tts/FastSpeech2_Multi/prosody_cloning.pt
    hifigan_path: !ref <models_dir>/tts/HiFiGAN_combined/best.pt
    embeddings_path: !ref <models_dir>/tts/Embedding/embedding_function.pt
    output_sr: 16000
    results_path: !ref <intermediate_dir>/anon_speech/ims_sttts_pc
